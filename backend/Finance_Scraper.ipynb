{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90b89702-69eb-4bcf-806d-fc5c30af0449",
   "metadata": {},
   "source": [
    "# Scrape for Committee's Contribution Records\n",
    "\n",
    "This notebook scrapes from the [Wayne County Finance System](https://wccampaignfinance.com/Public/ReceiptsList) for committees' contribution records and saves them into a CSV file called [contributions.csv](../data/contributions.csv) in the data folder. It should be noted that this process takes a long time, so it's recommended that this should only be run for a few minutes for testing. A sufficient amount of data had already been scraped and put into the contributions.csv file and is readily available for immediate use. This function is not efficient and can be prone to breaking if the loading time between each command is too long. \n",
    "\n",
    "The next function of this notebook will read data from the contributions.csv file and generate pie charts with dynamic hovering for a provided committee's name. Names that correspond to multiple zip codes will have multiple pie charts, one for each zip code. This is to ensure that different people with the same name are not grouped into the same pie chart.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454bd2c0-bc05-4669-8bd2-a7501b9151c5",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ec9e787-d628-4194-882b-fad845892788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selenium & WebDriver\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import FirefoxOptions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "\n",
    "# Others\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import re\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75078184-2015-406a-a467-52a196a1c76f",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f962d96-f738-452d-a2e8-f35aef4a8b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_driver():\n",
    "    '''\n",
    "    Initialize a Selenium Firefox WebDriver \n",
    "\n",
    "    Returns:\n",
    "    WebDriver: An instance of a Firefox WebDriver.\n",
    "                If the driver cannot be started in normal mode, it falls back to headless mode.\n",
    "                Returns the driver\n",
    "\n",
    "    Notes:\n",
    "    - The function attempts to start the driver in regular mode first. \n",
    "    - If there is an error starting the driver, it will attempt to start it in headless mode.\n",
    "    '''\n",
    "    gecko_path = shutil.which(\"geckodriver\")\n",
    "    service = Service(executable_path=gecko_path)\n",
    "    opts = webdriver.FirefoxOptions()\n",
    "    try: # Try starting a regular driver\n",
    "        driver = webdriver.Firefox(service=service, options=opts)\n",
    "    except: # If not possible, start a headless/invisible driver\n",
    "        opts.add_argument(\"--headless\")\n",
    "        driver = webdriver.Firefox(service=service, options=opts)\n",
    "        print('Headless/Invisible Driver')\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b21d3b82-314c-42d5-b976-dfa7c498a04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boot up a Firefox webdriver\n",
    "driver = get_driver() # This might take a while to boot up\n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://wccampaignfinance.com/Public/ReceiptsList\" # go to the Wayne County Contribution Record\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1857121-ab34-4bc7-81de-1b8a30abefb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "element = driver.find_element(By.XPATH, f\"//input[@id='btnContinue']\") # Click on the 'Continue' button\n",
    "element.click()\n",
    "time.sleep(3)\n",
    "\n",
    "element = driver.find_element(By.XPATH, f\"//select[@id='FilingPeriodName']\") # Click on the 'Reporting Period' dropdown menu\n",
    "element.click()\n",
    "time.sleep(1)\n",
    "\n",
    "element = element.find_element(By.XPATH, f\".//option[@value='']\") # Select the empty value in the dropdown to capture all periods\n",
    "element.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66a189a-b5a2-403d-ba5c-042d26d39621",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "official_df = pd.read_excel('../data/List_of_names_1_7_2.xlsx') #  # Read in the List of provided names csv\n",
    "def get_contribution_df(last_name, first_name, selenium_id, df=None):\n",
    "    \"\"\"\n",
    "    Scrapes and returns a DataFrame of contribution records for a given contributor using Selenium.\n",
    "\n",
    "    This function uses Selenium to search for a contributor by last and first name on a web form,\n",
    "    then extracts contribution data from the Wayne County Finance data system.\n",
    "\n",
    "    Parameters:\n",
    "        last_name (str): The last name of the contributor to search for.\n",
    "        first_name (str): The first name of the contributor to search for.\n",
    "        selenium_id (str): The HTML `id` of the table element containing the contributions data.\n",
    "        df (pd.DataFrame, optional): An existing DataFrame to append results to. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing all the contribution records found.\n",
    "    \"\"\"\n",
    "    def extract_table(selenium_id, df=None): # function to extract a table from an HTML id then return a pandas df   \n",
    "        element = driver.find_element(By.XPATH, f\"//table[@id='{selenium_id}']\").get_attribute('outerHTML') # get table from provided id\n",
    "        new_df = pd.read_html(StringIO(element))[0] # convert the HTML table element into a pandas table\n",
    "        if df is None: # If there's no previous table, then df is just the newly generated df \n",
    "            df = new_df\n",
    "        else: # If there is a previous df provided, concat the two tables together\n",
    "            df = pd.concat([df, new_df], ignore_index=True)\n",
    "        \n",
    "        try: # Try to click 'Next' on the page (for cases where a long record is broken up into multiple pages of content)\n",
    "            element = driver.find_element(By.XPATH, f\"//a[text()='Next >']\")\n",
    "            element.click()\n",
    "            time.sleep(5)\n",
    "            return extract_table(selenium_id, df) # recursively extract table on each page\n",
    "        except: # If there's no more pages, return the whole table\n",
    "            return df\n",
    "    element = driver.find_element(By.XPATH, f\"//input[@id='txtContributorName']\")\n",
    "    element.clear()\n",
    "    element.send_keys(last_name) # Fill in the last name of the committee\n",
    "    time.sleep(1)\n",
    "    \n",
    "    element = driver.find_element(By.XPATH, f\"//input[@id='txtFirstName']\") \n",
    "    element.clear() \n",
    "    element.send_keys(first_name) # Fill in the first name of the committee\n",
    "    time.sleep(1)\n",
    "    \n",
    "    element = driver.find_element(By.XPATH, f\"//input[@id='btnSearch']\") \n",
    "    element.click() # Click the 'Search' button\n",
    "    time.sleep(7)\n",
    "\n",
    "    return extract_table('LoadViewReceipts', df) # return the table for each committee\n",
    "\n",
    "df = None\n",
    "for index, row in official_df.iterrows(): # iterate through all the names in the provided dataset\n",
    "    df = get_contribution_df(row['Last'], row['First'], 'LoadViewReceipts', df) # extract contribution data for all names\n",
    "\n",
    "    # save the data into data/contributions.csv, uncomment the line below if you want to start a whole new scraping process\n",
    "    # df.to_csv('../data/contributions.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96da2275-ffe7-449a-8367-af54520c4581",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18afefb7-2fac-433a-9ac7-1463d2084b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_code_pattern = r'\\b([A-Z]{2})\\s(\\d{5})\\b' # The pattern is 2 letters for state code and 5 numbers for zip code \n",
    "\n",
    "contrs = pd.read_csv('../data/contributions.csv') # read in the contribution data saved in data/contributions.csv\n",
    "contrs = contrs.replace(\"No records to view.\", np.nan) # Replace every \"No records to view.\" with np.nan\n",
    "contrs.dropna(how='all', inplace=True) # Drop all rows that have no information\n",
    "\n",
    "# convert string into datetime object\n",
    "contrs['Transaction Date'] = contrs['Transaction Date'].apply(lambda x: datetime.strptime(x, '%m/%d/%Y').date()) \n",
    "# drop all the '$' symbol from the 'Contribution Amount' column and convert the value into float\n",
    "contrs['Contribution Amount'] = contrs['Contribution Amount'].apply(lambda x: float(x.translate(str.maketrans(\"\",\"\", \"$,\"))))\n",
    "# extract the zip code pattern from each address to make a new column called 'Contributor Zip Code'\n",
    "contrs['Contributor Zip Code'] = contrs['Contributor Address'].apply(lambda x: re.search(zip_code_pattern, x).group() \n",
    "                                                                     if isinstance(x, str) else 'Not Found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6594d85-ce30-4a50-8804-9fa1a476c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dynamic_chart(name):\n",
    "    \"\"\"\n",
    "    Generate and display a series of pie charts showing political contributions by a specific contributor.\n",
    "\n",
    "    For each unique ZIP code associated with the contributor's name, a separate pie chart is generated.\n",
    "    Each chart displays the total contributions to different receiving committees from that ZIP code,\n",
    "    with hover text providing detailed information about individual contributions.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    name : str\n",
    "        The (partial or full) name of the contributor to search for. Case-insensitive.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    str or None\n",
    "        Returns a message if no contributor is found with the given name.\n",
    "        Otherwise, displays an interactive Plotly figure and returns the data.\n",
    "    \"\"\" \n",
    "    subdf = contrs[contrs['Contributor Name'].str.contains(name, case=False)] # make a subdf that contains the provided contributor name\n",
    "    subdf = subdf.drop_duplicates() # drop all duplicate rows in subdf\n",
    "    zipcodes = subdf['Contributor Zip Code'].unique() # extract all unique zipcodes in the subdf\n",
    "    if len(zipcodes) == 0: # If there's no info found for the person, return a string that notifies such\n",
    "        return f\"No information found for {name}\"\n",
    "    \n",
    "    fig = make_subplots(rows=len(zipcodes), cols=1,\n",
    "                        specs=[[{'type': 'domain'}]] * len(zipcodes),\n",
    "                        subplot_titles=[f\"Zip Code: {z}\" for z in zipcodes]) # initiate the subplots \n",
    "    def make_hovertext(group): # function to make the displayed text when hovered\n",
    "        row_text = (f\"{row['Transaction Date']} | \"\n",
    "                    f\"${row['Contribution Amount']} | \"\n",
    "                    f\"{row['Contributor Type']} | \"\n",
    "                    f\"{row['Contribution Type']}<br>\" for _, row in group.iterrows())\n",
    "        rows = ''.join(row_text)\n",
    "        return rows # Hovered text contains the Transaction Date, Contribution Amount, Contributor Type, and Contribution Type\n",
    "        \n",
    "    for i, zipcode in enumerate(zipcodes): # iterate through all the unique zipcodes\n",
    "        zip_df = subdf[subdf['Contributor Zip Code'] == zipcode].sort_values('Transaction Date') # make a zip_df for each unique zip code\n",
    "        plot_df = zip_df.groupby('Receiving Committee')['Contribution Amount'].sum().reset_index() \n",
    "        hover_df = zip_df.groupby('Receiving Committee').apply(make_hovertext).reset_index(name='HoverText')\n",
    "        pie_data = pd.merge(plot_df, hover_df, on='Receiving Committee') # generate a df that's grouped by the receiving committee\n",
    "        fig.add_trace(go.Pie(\n",
    "            labels=pie_data['Receiving Committee'],\n",
    "            values=pie_data['Contribution Amount'],\n",
    "            rotation=90,\n",
    "            customdata=pie_data[['HoverText']].values,  # must be 2D array\n",
    "            hovertemplate=('<b>%{label}</b><br>Total: $%{value:,}<br><br>'\n",
    "                           '<i>Date | Amount | Contributor | Contribution</i><br>'\n",
    "                           '%{customdata[0]}<extra></extra>')\n",
    "        ), row=i+1, col=1) # make the pie chart with hovering\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=300 * len(zipcodes),  # Adjust based on number of charts\n",
    "        title_text=f\"Contributions by {name} per ZIP Code\",\n",
    "        showlegend=False\n",
    "    ) # adjust the layout\n",
    "    \n",
    "    fig.show() # show the pie charts\n",
    "    return subdf # return the subdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7638ebb-dbfa-45af-9d46-0e990920b783",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dynamic_chart(\"Mary Sheffield\") # generate pie chart for Mary Sheffield, change the name if needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
